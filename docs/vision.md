## 1. Технологии

- **Фреймворк:** Next.js (App Router)
- **Язык:** TypeScript
- **UI-библиотека:** React, ShadCN UI
- **Стилизация:** Tailwind CSS
- **База данных:** PostgreSQL (через Google Cloud SQL)
- **Хранилище файлов:** Google Cloud Storage (S3-совместимый API)
- **AI/LLM:** Google Genkit
- **Деплоймент:** Firebase App Hosting

## 2. Архитектура проекта

Проект строится на основе классической **трехслойной архитектуры**, адаптированной под Next.js App Router:

1.  **Слой представления (UI Layer):**
    -   Находится в `src/app` (страницы и компоненты) и `src/components`.
    -   Отвечает исключительно за отображение данных и взаимодействие с пользователем.
    -   Компоненты не содержат прямой бизнес-логики или запросов к базе данных. Они вызывают `Server Actions`.

2.  **Слой действий и сервисов (Actions & Services Layer):**
    -   Находится в `src/app/actions` и `src/lib/services`.
    -   `Actions` служат точкой входа для UI. Они валидируют данные и вызывают соответствующие сервисы.
    -   `Services` (например, `products.service.ts`) инкапсулируют бизнес-логику и являются единственным местом, где происходит работа с данными (CRUD). Это гарантирует, что UI отделен от деталей реализации хранилища.

3.  **Слой доступа к данным (Data Access Layer):**
    -   Представлен модулем `src/lib/db.ts` и `src/lib/s3-client.ts`.
    -   Обеспечивает низкоуровневое подключение и взаимодействие с PostgreSQL и S3.
    -   Сервисный слой использует этот модуль, полностью абстрагируясь от деталей подключения (будь то Cloud SQL Proxy или Unix-сокет в продакшене).

## 3. Модель данных и Роли

### 3.1. Основные сущности (Таблицы БД)

Модель данных спроектирована в реляционной парадигме и хранится в PostgreSQL. Ключевые сущности включают:

-   **Users:** Пользователи системы (клиенты, администраторы).
-   **Roles:** Роли пользователей (`admin`, `customer`).
-   **UserRoles:** Связующая таблица для назначения ролей.
-   **Products:** Каталог товаров со всеми характеристиками (цена, описание, SKU).
-   **Categories:** Иерархические категории товаров с префиксами для SKU.
-   **Orders:** Информация о заказах клиентов.
-   **OrderItems:** Позиции товаров внутри каждого заказа.
-   **Media:** Метаданные о файлах, загруженных в S3 (например, изображения товаров).

*Подробная схема находится в `docs/S3_SQL_instruction.md`.*

### 3.2. Ролевая модель (Права доступа)

Система будет поддерживать следующие роли с четким разделением прав:

1.  **Гость (неавторизованный пользователь):**
    -   Может: просматривать каталог, товары, категории; добавлять товары в корзину (корзина хранится на клиенте).
    -   Не может: оформлять заказ, просматривать историю заказов, заходить в админ-панель.

2.  **Клиент (Customer, авторизованный пользователь):**
    -   Может: всё, что может Гость, плюс оформлять заказы, просматривать свою историю заказов, управлять своим профилем.
    -   Не может: заходить в админ-панель.

3.  **Администратор (Admin):**
    -   Может: всё, что может Клиент, плюс полный доступ к админ-панели (`/admin`) для управления товарами, категориями, заказами и просмотра системных логов.

*На текущем этапе аутентификация и разделение ролей не реализованы. Все пользователи фактически имеют права Гостя. Админ-панель открыта для доступа без авторизации. Это будет исправлено на следующих этапах разработки.*

# 4. Работа с LLM

Работа с генеративным AI будет строиться на двух уровнях, чтобы обеспечить гибкость на старте и масштабируемость в будущем.

## 4.1. Идеальная архитектура (Vision)

В долгосрочной перспективе, вся логика, связанная с LLM, будет инкапсулирована в виде атомарных, переиспользуемых модулей — **"Потоков" (Flows)**. Эта архитектура защитит систему от рисков и обеспечит предсказуемость.

### Технический стек
- **Основной инструмент:** Google Genkit. Это единый фреймворк для всех AI-операций.
- **Поставщик моделей:** Google Vertex AI (Gemini Pro), но Genkit позволяет легко переключаться на других провайдеров.
- **Слой абстракции:** Между бизнес-логикой и Genkit для возможности смены фреймворка без переписывания кода.

### Принципы работы
1. **Изоляция:** Каждый "Поток" (например, `substituteProductFlow.ts`) решает одну конкретную задачу, не имея прямого доступа к базе данных или другим частям системы.

2. **Структурированный вывод:** Все потоки возвращают данные в формате JSON, строго соответствующем Zod-схемам. Это исключает работу с "сырым" текстом.

3. **Контроль контекста:** Вся информация передается модели через входные данные потока.

4. **Инструменты (Tools):** Для выполнения сложных задач (например, проверки наличия товара) LLM получает доступ к специально разработанным инструментам, а не к бизнес-логике напрямую.

5. **Аудит и логирование:** Каждый вызов LLM логируется для отладки, мониторинга и анализа стоимости.

6. **Стратегия отката:** При сбое LLM-потока система автоматически переходит к резервному поведению, чтобы не прерывать пользовательский опыт.

### Архитектура результата
```typescript
interface RecommendationResult {
  suggestions: Product[];
  source: 'llm' | 'rules' | 'fallback';
  confidence: number;
  cost?: number;
  processingTime: number;
}
```

## 4.2. Прагматичный план для MVP

Для быстрого старта и проверки гипотез используем **гибридный подход**, сочетающий LLM с простыми эвристическими правилами.

### Стратегия внедрения

**1. Начинаем с малого**
Сосредоточимся на создании 1-2 ключевых LLM-потоков:
- `substituteProductFlow`: Умная замена отсутствующих товаров
- `optimizeWeeklyCartFlow`: Оптимизация еженедельной корзины

**2. Сначала — эвристика**
Для простых задач (например, "предложить похожий товар из той же категории") используем обычную бизнес-логику без вызова LLM. Это быстрее и дешевле.

**3. Критерии перехода от правил к LLM**
- Если accuracy простых правил < 70% — переводим на LLM
- Если cost per conversion через LLM > 500₽ — возвращаемся к правилам
- Если время ответа > 3 секунд — оптимизируем или возвращаемся к правилам

### Контроль рисков и бюджета

**Budget Control:**
- Максимум 1000 вызовов LLM на пользователя в день
- Circuit breaker при превышении месячного лимита затрат на AI
- Автоматическое переключение на правила при достижении лимитов

**Мониторинг метрик:**

*Технические метрики:*
- Время ответа LLM (target: <2 сек)
- Стоимость на запрос
- Частота fallback'ов на простые правила
- Процент успешных вызовов LLM

*Бизнес-метрики:*
- Конверсия рекомендаций в покупки
- User satisfaction с рекомендациями
- ROI от использования LLM vs простых алгоритмов
- Increase в среднем чеке благодаря LLM

### A/B тестирование

Для каждой задачи будем тестировать три подхода:
- **Группа A:** Только простые правила
- **Группа B:** LLM + fallback на правила
- **Контрольная группа:** Без рекомендаций

Критерии успеха для перехода на LLM:
- Конверсия в группе B > группы A минимум на 15%
- Увеличение среднего чека в группе B минимум на 10%
- Cost per acquisition через LLM не превышает маржинальность

## 4.3. План поэтапного внедрения

### Неделя 1-2: Базовые правила
- Реализация простых эвристических правил для всех задач
- Настройка мониторинга базовых метрик
- Подготовка инфраструктуры для A/B тестирования

### Неделя 3-4: Первый LLM поток
- Интеграция `substituteProductFlow` для замены товаров
- Настройка логирования и fallback стратегии
- Запуск A/B теста: LLM vs правила

### Неделя 5-8: Измерение и оптимизация
- Анализ результатов A/B теста
- Оптимизация промптов и логики
- Настройка budget controls

### Неделя 9+: Масштабирование
- Если ROI положительный — добавление следующего потока
- Постепенное увеличение доли LLM-рекомендаций
- Переход к полноценной архитектуре Flows

## 4.4. Технические детали реализации

### Структура абстракции
```typescript
interface AIRecommendationService {
  getProductSubstitutes(product: Product, userPreferences: UserPreferences): Promise<RecommendationResult>;
  optimizeWeeklyCart(currentCart: CartItem[], userHistory: Order[]): Promise<RecommendationResult>;
}

// Реализации
class SimpleRulesService implements AIRecommendationService { ... }
class LLMBasedService implements AIRecommendationService { ... }
class HybridService implements AIRecommendationService { ... }
```

### Fallback стратегия
1. **Первичный:** Вызов LLM
2. **Вторичный:** Простые правила при сбое LLM
3. **Финальный:** Статичные рекомендации при полном сбое системы

Такой подход обеспечит **гибкость** для быстрого тестирования гипотез, сохраняя при этом **продуманный план** для масштабирования в будущем.
